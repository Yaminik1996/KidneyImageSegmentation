{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pathlib, sys, os, random, time\nimport numba, cv2, gc\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T04:53:07.951382Z","iopub.execute_input":"2021-11-28T04:53:07.951726Z","iopub.status.idle":"2021-11-28T04:53:07.962855Z","shell.execute_reply.started":"2021-11-28T04:53:07.951689Z","shell.execute_reply":"2021-11-28T04:53:07.961671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import rasterio\nfrom rasterio.windows import Window","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:53:09.438172Z","iopub.execute_input":"2021-11-28T04:53:09.438488Z","iopub.status.idle":"2021-11-28T04:53:09.442667Z","shell.execute_reply.started":"2021-11-28T04:53:09.438456Z","shell.execute_reply":"2021-11-28T04:53:09.441624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as D\n\nimport torchvision\nfrom torchvision import transforms as T","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:53:11.604352Z","iopub.execute_input":"2021-11-28T04:53:11.60479Z","iopub.status.idle":"2021-11-28T04:53:11.609951Z","shell.execute_reply.started":"2021-11-28T04:53:11.60474Z","shell.execute_reply":"2021-11-28T04:53:11.608886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seeds(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seeds();","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-11-28T04:53:13.445648Z","iopub.execute_input":"2021-11-28T04:53:13.445992Z","iopub.status.idle":"2021-11-28T04:53:13.452157Z","shell.execute_reply.started":"2021-11-28T04:53:13.445959Z","shell.execute_reply":"2021-11-28T04:53:13.451312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = '../input/hubmap-kidney-segmentation'\nEPOCHES = 15\nBATCH_SIZE = 32\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' ","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:53:15.848297Z","iopub.execute_input":"2021-11-28T04:53:15.848646Z","iopub.status.idle":"2021-11-28T04:53:15.853101Z","shell.execute_reply.started":"2021-11-28T04:53:15.848591Z","shell.execute_reply":"2021-11-28T04:53:15.852131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# used for converting the decoded image to rle mask\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(256, 256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n\ndef rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_grid(shape, window=256, min_overlap=32):\n    \"\"\"\n        Return Array of size (N,4), where N - number of tiles,\n        2nd axis represente slices: x1,x2,y1,y2 \n    \"\"\"\n    x, y = shape\n    nx = x // (window - min_overlap) + 1\n    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n    x1[-1] = x - window\n    x2 = (x1 + window).clip(0, x)\n    ny = y // (window - min_overlap) + 1\n    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n    y1[-1] = y - window\n    y2 = (y1 + window).clip(0, y)\n    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n    \n    for i in range(nx):\n        for j in range(ny):\n            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n    return slices.reshape(nx*ny,4)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:53:21.48914Z","iopub.execute_input":"2021-11-28T04:53:21.489473Z","iopub.status.idle":"2021-11-28T04:53:21.50908Z","shell.execute_reply.started":"2021-11-28T04:53:21.48944Z","shell.execute_reply":"2021-11-28T04:53:21.508096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n\nclass HubDataset(D.Dataset):\n\n    def __init__(self, root_dir, transform,\n                 window=256, overlap=64, threshold = 500):\n        self.path = pathlib.Path(root_dir)\n        self.overlap = overlap\n        self.window = window\n        self.transform = transform\n        self.csv = pd.read_csv((self.path / 'train.csv').as_posix(),\n                               index_col=[0])\n        self.threshold = threshold\n        self.build_slices()\n        self.len = len(self.slices)\n        self.as_tensor = T.Compose([\n            T.ToTensor(),\n            T.Normalize([0.625, 0.448, 0.688],\n                        [0.131, 0.177, 0.101]),\n        ])\n    def build_slices(self):\n        self.masks = []\n        self.files = []\n        self.slices = []\n        for i, filename in enumerate(self.csv.index.values):\n            filepath = (self.path /'train'/(filename+'.tiff')).as_posix()\n            self.files.append(filepath)\n            with rasterio.open(filepath, transform = identity) as dataset:\n                self.masks.append(rle_decode(\n                    self.csv.loc[filename, 'encoding'], dataset.shape))\n                slices = make_grid(dataset.shape, window=self.window,\n                                   min_overlap=self.overlap)\n                for slc in slices:\n                    x1,x2,y1,y2 = slc\n                    if dataset.read(1, window=Window.from_slices((x1,x2),(y1,y2))).sum() == 0:\n                        continue\n                    if self.masks[-1][x1:x2,y1:y2].sum() > self.threshold or random.random() < 0.2:\n                        self.slices.append([i,x1,x2,y1,y2])\n                        \n    # get data operation\n    def __getitem__(self, index):\n        \n        idx = self.slices[index][0]\n        filename = self.files[idx]\n        x1,x2,y1,y2 = self.slices[index][1:] \n        with rasterio.open(filename, transform = identity) as dataset:\n            channels = [1,2,3] if dataset.count == 3 else [1,1,1]\n            image = dataset.read(channels,window=Window.from_slices((x1,x2),(y1,y2)))    \n            image = np.moveaxis(image, 0, -1)\n            \n        mask = self.masks[idx][x1:x2,y1:y2]\n        \n        augments = self.transform(image=image, mask=mask)\n        return self.as_tensor(augments['image']), augments['mask'][None]\n    \n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:53:24.175463Z","iopub.execute_input":"2021-11-28T04:53:24.176119Z","iopub.status.idle":"2021-11-28T04:53:24.211553Z","shell.execute_reply.started":"2021-11-28T04:53:24.17607Z","shell.execute_reply":"2021-11-28T04:53:24.210464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WINDOW=1024\nMIN_OVERLAP=32\nNEW_SIZE=256\n\ntrfm = A.Compose([\n    A.Resize(NEW_SIZE,NEW_SIZE),\n    A.HorizontalFlip(p=0.5),\n    A.ColorJitter (brightness=0.07, contrast=0.07,\n                   saturation=0.1, hue=0.1, always_apply=False, p=0.3)\n])\n\nds = HubDataset(DATA_PATH, window=WINDOW, overlap=MIN_OVERLAP, transform=trfm)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:53:27.197206Z","iopub.execute_input":"2021-11-28T04:53:27.197529Z","iopub.status.idle":"2021-11-28T04:59:48.252227Z","shell.execute_reply.started":"2021-11-28T04:53:27.197497Z","shell.execute_reply":"2021-11-28T04:59:48.251391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_idx, train_idx = [], []\nfor i in range(len(ds)):\n    if ds.slices[i][0] == 7:\n        valid_idx.append(i)\n    else:\n        train_idx.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:01:35.131202Z","iopub.execute_input":"2021-11-28T05:01:35.131648Z","iopub.status.idle":"2021-11-28T05:01:35.140161Z","shell.execute_reply.started":"2021-11-28T05:01:35.131592Z","shell.execute_reply":"2021-11-28T05:01:35.13932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = D.Subset(ds, train_idx)\nvalid_ds = D.Subset(ds, valid_idx)\n\n# define training and validation data loaders\nloader = D.DataLoader(\n    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n\nvloader = D.DataLoader(\n    valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:01:36.849309Z","iopub.execute_input":"2021-11-28T05:01:36.849661Z","iopub.status.idle":"2021-11-28T05:01:36.855464Z","shell.execute_reply.started":"2021-11-28T05:01:36.849626Z","shell.execute_reply":"2021-11-28T05:01:36.854374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model = torchvision.models.segmentation.fcn_resnet50(True)\n    model.classifier[4] = nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n    model.aux_classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:01:39.133221Z","iopub.execute_input":"2021-11-28T05:01:39.133534Z","iopub.status.idle":"2021-11-28T05:01:39.13995Z","shell.execute_reply.started":"2021-11-28T05:01:39.133503Z","shell.execute_reply":"2021-11-28T05:01:39.139027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef validation(model, loader, loss_fn):\n    losses = []\n    model.eval()\n    for image, target in loader:\n        image, target = image.to(DEVICE), target.float().to(DEVICE)\n        output = model(image)['out']\n        loss = loss_fn(output, target)\n        losses.append(loss.item())\n        \n    return np.array(losses).mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:01:41.220438Z","iopub.execute_input":"2021-11-28T05:01:41.220789Z","iopub.status.idle":"2021-11-28T05:01:41.227794Z","shell.execute_reply.started":"2021-11-28T05:01:41.220755Z","shell.execute_reply":"2021-11-28T05:01:41.226685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# deeplabv3_resnet101_coco-586e9e4e.pth  fcn_resnet50_coco-1167a1af.pth\n# deeplabv3_resnet50_coco-cd0a2569.pth   resnet101-5d3b4d8f.pth\n# fcn_resnet101_coco-7ecb50ca.pth        resnet50-19c8e357.pth\n# Copy pretrain weight for model to cache dir\n!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/pytorch-pretrained-models/resnet50-19c8e357.pth /root/.cache/torch/hub/checkpoints/\n!cp ../input/pretrain-coco-weights-pytorch/fcn_resnet50_coco-1167a1af.pth /root/.cache/torch/hub/checkpoints/","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:01:43.17039Z","iopub.execute_input":"2021-11-28T05:01:43.170727Z","iopub.status.idle":"2021-11-28T05:01:50.510382Z","shell.execute_reply.started":"2021-11-28T05:01:43.170694Z","shell.execute_reply":"2021-11-28T05:01:50.509376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\n\nmodel.to(DEVICE);\n\noptimizer = torch.optim.AdamW(model.parameters(),\n                  lr=1e-3, weight_decay=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:04:05.621049Z","iopub.execute_input":"2021-11-28T05:04:05.621415Z","iopub.status.idle":"2021-11-28T05:04:06.844995Z","shell.execute_reply.started":"2021-11-28T05:04:05.621378Z","shell.execute_reply":"2021-11-28T05:04:06.844044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Table for results\nheader = r'''\n        Train | Valid\nEpoch |  Loss |  Loss | Time, m\n'''\n#          Epoch         metrics            time\nraw_line = '{:6d}' + '\\u2502{:7.3f}'*2 + '\\u2502{:6.2f}'","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:04:08.351663Z","iopub.execute_input":"2021-11-28T05:04:08.352001Z","iopub.status.idle":"2021-11-28T05:04:08.356447Z","shell.execute_reply.started":"2021-11-28T05:04:08.351967Z","shell.execute_reply":"2021-11-28T05:04:08.355274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SoftDiceLoss(nn.Module):\n    def __init__(self, smooth=1., dims=(-2,-1)):\n\n        super(SoftDiceLoss, self).__init__()\n        self.smooth = smooth\n        self.dims = dims\n    \n    def forward(self, x, y):\n\n        tp = (x * y).sum(self.dims)\n        fp = (x * (1 - y)).sum(self.dims)\n        fn = ((1 - x) * y).sum(self.dims)\n        \n        dc = (2 * tp + self.smooth) / (2 * tp + fp + fn + self.smooth)\n        dc = dc.mean()\n\n        return 1 - dc","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:04:59.987315Z","iopub.execute_input":"2021-11-28T05:04:59.987661Z","iopub.status.idle":"2021-11-28T05:04:59.996159Z","shell.execute_reply.started":"2021-11-28T05:04:59.987627Z","shell.execute_reply":"2021-11-28T05:04:59.995035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train using weighted loss and print both losses\nbce_fn = nn.BCEWithLogitsLoss()\ndice_fn = SoftDiceLoss()\n\ndef loss_fn(y_pred, y_true):\n    bce = bce_fn(y_pred, y_true)\n    dice = dice_fn(y_pred.sigmoid(), y_true)\n    return 0.8*bce+ 0.2*dice\n\ndef dice_loss_cal(y_pred, y_true):\n    return dice_fn(y_pred.sigmoid(), y_true)\n\nprint(header)\n\nbest_loss = float('inf')\nfor epoch in range(1, EPOCHES + 1):\n    losses = []\n    dices = []\n    accuracies = []\n    start_time = time.time()\n    model.train()\n    for image, target in loader:\n        \n        image, target = image.to(DEVICE), target.float().to(DEVICE)\n        optimizer.zero_grad()\n        output = model(image)['out']\n        accuracy = torch.sum(output == target)//output.numel()\n        accuracy = accuracy.cpu().detach().numpy().item()\n        loss = loss_fn(output, target)\n        dice_loss = dice_loss_cal(output, target)\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n        dices.append(dice_loss.item())\n        accuracies.append(accuracy)\n    vloss = validation(model, vloader, loss_fn)\n    vdloss = validation(model, vloader, dice_loss_cal)\n    print(raw_line.format(epoch, np.array(losses).mean(), vloss,\n                              (time.time()-start_time)/60**1))\n    print(\"Dice: \")\n    print(raw_line.format(epoch, np.array(dices).mean(), vdloss,\n                              (time.time()-start_time)/60**1))\n    print(\"Accuracy: \")\n    print(np.array(accuracies).mean())\n    losses = []\n    dices = []\n    accuracies = []","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:06:16.371376Z","iopub.execute_input":"2021-11-28T05:06:16.371732Z","iopub.status.idle":"2021-11-28T05:06:30.100998Z","shell.execute_reply.started":"2021-11-28T05:06:16.371697Z","shell.execute_reply":"2021-11-28T05:06:30.099363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train using dice loss and print both losses \nbest_loss = float('inf')\nfor epoch in range(1, EPOCHES+1):\n    losses = []\n    dices = []\n    accuracies = []\n    start_time = time.time()\n    model.train()\n    for image, target in loader:\n        \n        image, target = image.to(DEVICE), target.float().to(DEVICE)\n        optimizer.zero_grad()\n        output = model(image)['out']\n        accuracy = torch.sum(output == target)//output.numel()\n        accuracy = accuracy.cpu().detach().numpy().item()\n        loss = loss_fn(output, target)\n        dice_loss = dice_loss_cal(output, target)\n        dice_loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n        dices.append(dice_loss.item())\n        accuracies.append(accuracy)\n    vloss = validation(model, vloader, loss_fn)\n    vdloss = validation(model, vloader, dice_loss_cal)\n    print(raw_line.format(epoch, np.array(dices).mean(), vdloss,\n                              (time.time()-start_time)/60**1))\n    print(\"Weighted loss:\")\n    print(raw_line.format(epoch, np.array(losses).mean(), vloss,\n                              (time.time()-start_time)/60**1))\n    print(\"Accuracy: \")\n    print(np.array(accuracies).mean())\n    losses = []\n    dices = []\n    accuracies = []","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:35:30.758977Z","iopub.status.idle":"2021-11-28T04:35:30.759725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del train set\ndel loader, vloader, train_ds, valid_ds, ds\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:35:30.760884Z","iopub.status.idle":"2021-11-28T04:35:30.761589Z"},"trusted":true},"execution_count":null,"outputs":[]}]}